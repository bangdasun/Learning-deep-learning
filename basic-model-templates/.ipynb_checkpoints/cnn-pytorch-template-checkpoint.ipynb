{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e95742acd51c88f73e15112f03346f828589e3dd"
   },
   "source": [
    "## CNN Model Template (pytorch)\n",
    "\n",
    "* Use `mnist` image dataset, build a CNN for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "cae869f61205f42b3963578e5424b3c8079da8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(29400, 784) (12600, 784) (29400,) (12600,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "print(train.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.iloc[:, 1:].values,\n",
    "    train.iloc[:, 0].values,\n",
    "    test_size=0.3,\n",
    "    random_state=2019\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4281df8ec762461c435367774146baf5c450cd9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 1, 28, 28) (12600, 1, 28, 28) (29400, 10) (12600, 10)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, img_rows, img_cols)\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5761c05cb3224ded9c44d1e15f53e69685538fc7"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Network structure definition (pytorch based)\n",
    "    \n",
    "    Some nn.{Layer} could be replaced with functions F.{func}:\n",
    "    nn.MaxPool2d, nn.Softmax, etc.\n",
    "    \n",
    "    Need to specifiy input_size and output_size for each layer.\n",
    "    For conv layer, out_channel is equivalent to num_filters in keras conv layers.\n",
    "    \n",
    "    conv2d: output_size = (inp_size - kernel_size + padding * 2) / stride + 1\n",
    "    flatten conv2d - maxpool2d: kernel_size * kernel_size * num_filters\n",
    "    \"\"\"\n",
    "    def __init__(self, model_params):\n",
    "        super().__init__()\n",
    "        # parameters\n",
    "        self.model_params = model_params\n",
    "        dropout_rate = self.model_params['dropout_rate']\n",
    "        \n",
    "        # layers (number of hidden units are hard-coded)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(in_features=4*4*128, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=100)\n",
    "        self.fc3 = nn.Linear(in_features=100, out_features=10)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        # reshape - Flatten layer\n",
    "        x = x.view(-1, 4 * 4 * 128)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.softmax(self.fc3(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bc85ad0b7e8aa00e1ebb3f7c4da961a070565e98"
   },
   "outputs": [],
   "source": [
    "class BasicNN(ABC):\n",
    "    @abstractmethod\n",
    "    def initialize(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save(self):\n",
    "        pass\n",
    "    \n",
    "class BaiscCNN(BasicNN):\n",
    "    \"\"\" Basic CNN model (pytorch) \"\"\"\n",
    "    def __init__(self, network, model_params):\n",
    "        self._model = network\n",
    "        self._out_size = list(self._model.parameters())[-1].size()[0]\n",
    "        self.model_params = model_params\n",
    "        \n",
    "    def initialize(self):\n",
    "        raise NotImplementedError(\"Method .initialized() not implemented.\")\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        self.train_params = self.model_params['train_params']\n",
    "        self.nb_epochs = self.train_params['nb_epochs']\n",
    "        self.batch_size = self.train_params['batch_size']\n",
    "        self.loss_fn = self.model_params['loss_fn']\n",
    "        self.optimizer = self.model_params['optimizer']\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).cuda()\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).cuda()\n",
    "        X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32).cuda()\n",
    "        y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32).cuda()\n",
    "        train_tensor = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        valid_tensor = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "        train_loader = torch.utils.data.DataLoader(train_tensor, batch_size=self.batch_size)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_tensor, batch_size=self.batch_size)\n",
    "        \n",
    "        self._model.cuda()\n",
    "        \n",
    "        for epoch in range(self.nb_epochs):\n",
    "            self._model.train()\n",
    "            avg_train_loss = 0\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                # back-prop: calculate loss, use optimizer to update trainable params\n",
    "                y_pred = self._model(x_batch)\n",
    "                loss = self.loss_fn(y_pred, y_batch)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                avg_train_loss += loss.item() / len(train_loader)\n",
    "            self._model.eval()\n",
    "            valid_preds_fold = np.zeros((X_valid_tensor.size(0)))\n",
    "            avg_val_loss = 0\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "                # calculate validation loss\n",
    "                y_pred = self._model(x_batch).detach()\n",
    "                loss = self.loss_fn(y_pred, y_batch)\n",
    "                avg_val_loss += loss.item() / len(valid_loader)\n",
    "            \n",
    "            print(f'Epoch {str(epoch+1):3s}/  {str(self.nb_epochs):3s}'\n",
    "                  f' train_loss = {avg_train_loss:.5f} valid_loss = {avg_val_loss:.5f}')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        test_preds = np.zeros((X.shape[0], self._out_size))\n",
    "        X_test_tensor = torch.tensor(X, dtype=torch.float32).cuda()\n",
    "        test_tensor = torch.utils.data.TensorDataset(X_test_tensor)\n",
    "        test_loader = torch.utils.data.DataLoader(test_tensor, batch_size=self.batch_size, shuffle=False)\n",
    "        for i, (x_batch, ) in enumerate(test_loader):\n",
    "            y_pred = self._model(x_batch).detach()\n",
    "            test_preds[i*(batch_size):(i+1)*(batch_size)] = y_pred.cpu().numpy()\n",
    "        return test_preds\n",
    "           \n",
    "    def save(self, saved_model_destination):\n",
    "        self.saved_model_destination = saved_model_destination\n",
    "        self._state_dict = self._model.state_dict()\n",
    "        torch.save(self._state_dict, self.saved_model_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "973d75305e7c318a8f2a1a10b2c5f50a457f8ddc"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'train_params': {'batch_size': 128,\n",
    "                     'patience'  : 10,\n",
    "                     'nb_epochs' : 10},\n",
    "    'loss_fn'     : nn.BCEWithLogitsLoss(reduction='sum'),\n",
    "    'dropout_rate': 0.5,\n",
    "}\n",
    "\n",
    "network = Network(model_params)\n",
    "model_params['optimizer'] = optim.Adam(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9c4d02a895d60594ff8bcc269fc94a19118b087d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  /  10  train_loss = 866.40916 valid_loss = 840.04294\n",
      "Epoch 2  /  10  train_loss = 844.98896 valid_loss = 837.61317\n",
      "Epoch 3  /  10  train_loss = 842.53257 valid_loss = 836.92374\n",
      "Epoch 4  /  10  train_loss = 841.63790 valid_loss = 837.41705\n",
      "Epoch 5  /  10  train_loss = 841.05909 valid_loss = 836.34534\n",
      "Epoch 6  /  10  train_loss = 840.72285 valid_loss = 836.07681\n",
      "Epoch 7  /  10  train_loss = 840.47727 valid_loss = 836.58970\n",
      "Epoch 8  /  10  train_loss = 840.13513 valid_loss = 835.87560\n",
      "Epoch 9  /  10  train_loss = 839.90453 valid_loss = 835.72339\n",
      "Epoch 10 /  10  train_loss = 839.82816 valid_loss = 835.86436\n"
     ]
    }
   ],
   "source": [
    "model = BaiscCNN(network, model_params)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "bc8a32fb3e1de0fc1b60f53d18eeebaeb0907811"
   },
   "outputs": [],
   "source": [
    "model.save('./basic_cnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
