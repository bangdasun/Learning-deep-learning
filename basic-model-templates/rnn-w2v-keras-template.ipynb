{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "### RNN Model (with pretrained Word2Vec) Template (keras)\n",
    "\n",
    "Use Quora Insincere Questions Classification competition data and pretrain Word2Vec (GloVe), build a RNN for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "dd440c6f8513571b8a92f371787651abd10e4dbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Embedding, CuDNNGRU, CuDNNLSTM\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, Dropout\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "fab98c8b04a4d73d3a8161412eea53ec27c09378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914285,) (391837,) (914285,) (391837,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "X, y = train['question_text'].values, train['target'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, test_size=0.3, random_state=2019)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e2a0f6dc20bd8404b9b9121c80f6a011276c031c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_len = np.array([len(x) for x in X_train])\n",
    "_, _, _ = plt.hist(X_train_len, bins=80)\n",
    "_ = plt.title('Distribution of text length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c562107155cc3cd8d43607a501a736bcb8c864fc"
   },
   "outputs": [],
   "source": [
    "embedding_filepath = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "\n",
    "def preprocessing(X_train, X_test, **kwargs):\n",
    "    \"\"\"\n",
    "    Preprocessing for text data\n",
    "    raw text -> tokenization -> raw sequence -> equal length sequence\n",
    "    \"\"\"\n",
    "    max_features = kwargs['max_features']\n",
    "    max_len = kwargs['max_len']\n",
    "    tokenizer = text.Tokenizer(num_words=max_features, lower=True, split=' ',\n",
    "                               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                               char_level=False, oov_token=None, document_count=0)\n",
    "    tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "    # convert text to sequence\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    # truncate and padding\n",
    "    X_train_seq_pad = sequence.pad_sequences(X_train_seq, maxlen=max_len)\n",
    "    X_test_seq_pad = sequence.pad_sequences(X_test_seq, maxlen=max_len)\n",
    "    \n",
    "    return X_train_seq, X_test_seq, X_train_seq_pad, X_test_seq_pad, tokenizer\n",
    "\n",
    "def load_embeddings(embedding_filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Load pretrained word embeddings (GloVe)\n",
    "    \n",
    "    :return: np.array, embeddings_matrix with shape (num_words, embeddings_size)\n",
    "    \"\"\"\n",
    "    embedding_size = kwargs['embeddings_size']\n",
    "    tokenizer = kwargs['tokenizer']\n",
    "    max_features = kwargs['max_features']\n",
    "    \n",
    "    def get_coefs(word, *arr):\n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*o.strip().rsplit(' ')) for o in open(embedding_filepath))\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min(max_features, len(word_index))\n",
    "    embeddings_matrix = np.zeros((num_words, embedding_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embeddings_vector = embeddings_index.get(word)\n",
    "        # oov or not\n",
    "        if embeddings_vector is not None:\n",
    "            embeddings_matrix[i] = embeddings_vector\n",
    "    \n",
    "    return embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6af4ed27cc33238ef93299be98f973ea9068590e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 sentences length:\n",
      "\n",
      "11\n",
      "10\n",
      "23\n",
      "\n",
      "\n",
      "\n",
      "sentence sequence example:\n",
      "\n",
      "['What are the pros and cons of living in Jakarta?'\n",
      " 'Why is there no outrage over hanging of a BJP worker in West Bengal? What about the note they found with the body?']\n"
     ]
    }
   ],
   "source": [
    "print('First 3 sentences length:\\n')\n",
    "for i in range(3):\n",
    "    print(len(X_train[i].split()))\n",
    "    \n",
    "print('\\n\\n')\n",
    "print('sentence sequence example:\\n')\n",
    "print(X_train[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7b46b01056ab7c962389e98b6221918eaefd449b"
   },
   "outputs": [],
   "source": [
    "X_train_seq, X_val_seq, X_train_seq_pad, X_val_seq_pad, tokenizer = \\\n",
    "        preprocessing(X_train, X_val, max_features=200000, max_len=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "cfe211bbc16eddd7956fff46aa729a6d80d34a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing, first 3 sentences length:\n",
      "\n",
      "11\n",
      "10\n",
      "23\n",
      "\n",
      "\n",
      "\n",
      "After preprocessing, sentence sequence example\n",
      "\n",
      "[[16, 3, 39, 105, 11303, 136, 5283, 7, 4, 1123, 3479, 6, 861, 2586, 2, 45, 1, 1818, 47, 436, 21, 1, 293], [16, 11, 951, 2694, 99430, 129, 62]]\n",
      "\n",
      "\n",
      "\n",
      "After preprocessing, first 3 sentences length after padding:\n",
      "\n",
      "70\n",
      "70\n",
      "70\n",
      "\n",
      "\n",
      "\n",
      "After preprocessing, sentence sequence example after padding\n",
      "\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0    16\n",
      "      3    39   105 11303   136  5283     7     4  1123  3479     6   861\n",
      "   2586     2    45     1  1818    47   436    21     1   293]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    16    11   951  2694 99430   129    62]]\n"
     ]
    }
   ],
   "source": [
    "print('After preprocessing, first 3 sentences length:\\n')\n",
    "for i in range(3):\n",
    "    print(len(X_train_seq[i]))\n",
    "print('\\n\\n')\n",
    "print('After preprocessing, sentence sequence example\\n')\n",
    "print(X_train_seq[2:4])\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('After preprocessing, first 3 sentences length after padding:\\n')\n",
    "for i in range(3):\n",
    "    print(len(X_train_seq_pad[i]))\n",
    "print('\\n\\n')\n",
    "print('After preprocessing, sentence sequence example after padding\\n')\n",
    "print(X_train_seq_pad[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f00e4029963c128c3d61252317f14d747dbcf3f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 300)\n"
     ]
    }
   ],
   "source": [
    "embeddings_lookup_matrix = load_embeddings(embedding_filepath,\n",
    "                                           embeddings_size=300,\n",
    "                                           max_features=200000,\n",
    "                                           tokenizer=tokenizer)\n",
    "print(embeddings_lookup_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "28bd65fbd44ed59958bca809e3ffaa125cf3789b"
   },
   "outputs": [],
   "source": [
    "def make_model(model_params):\n",
    "    \"\"\"\n",
    "    Template for build NN (RNN - GRU/LSTM) model (keras)\n",
    "    \n",
    "    :param model_params: dict, include\n",
    "                               - input_size: tuple for input shape\n",
    "                               - output_size: number of output units\n",
    "                               - max_features: number of words used\n",
    "                               - embedding_size: length of word vector\n",
    "                               - embeddings_matrix: embeddings lookup matrix\n",
    "                               - drop_rate: dropout rate\n",
    "                               - loss: loss function\n",
    "                               - optimizer: optimization method\n",
    "                               - metrics: list of metrics\n",
    "\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "    input_size = model_params['input_size']\n",
    "    output_size = model_params['output_size']\n",
    "    max_features = model_params['max_features']\n",
    "    embeddings_size = model_params['embeddings_size']\n",
    "    embeddings_matrix = model_params['embeddings_matrix']\n",
    "    drop_rate = model_params['drop_rate']\n",
    "    loss = model_params['loss']\n",
    "    optimizer = model_params['optimizer']\n",
    "    metrics = model_params['metrics']\n",
    "    \n",
    "    inp = Input(shape=input_size)\n",
    "    x = inp\n",
    "    x = Embedding(input_dim=max_features,\n",
    "                  output_dim=embeddings_size,\n",
    "                  trainable=False,\n",
    "                  weights=[embeddings_matrix])(x)\n",
    "    x = CuDNNLSTM(units=60,\n",
    "                  return_sequences=True)(x)\n",
    "    x = Conv1D(filters=32,\n",
    "               kernel_size=3,\n",
    "               padding='valid')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(units=64, activation='relu')(x)\n",
    "    x = Dropout(rate=drop_rate)(x)\n",
    "    x = Dense(units=output_size, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[inp], outputs=x)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "7774bec2b4b36b91dbaee9324d5cb18799ec983f"
   },
   "outputs": [],
   "source": [
    "class BasicNN(ABC):\n",
    "    @abstractmethod\n",
    "    def initialize(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save(self):\n",
    "        pass\n",
    "    \n",
    "class BasicRNN(BasicNN):\n",
    "    \"\"\" Basic RNN model (keras) \"\"\"\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\" Initialize model \"\"\"\n",
    "        model = make_model(self.model_params)\n",
    "        print('Model Summary:')\n",
    "        print(model.summary())\n",
    "        self._model = model\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        assert self._model is not None\n",
    "        self.train_params = self.model_params['train_params']\n",
    "        self.patience = self.train_params['patience']\n",
    "        self.nb_epochs = self.train_params['nb_epochs']\n",
    "        self.batch_size = self.train_params['batch_size']\n",
    "        self.filepath = self.model_params['filepath']\n",
    "        earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                                      patience=self.patience,\n",
    "                                      mode='min')\n",
    "        checkpointer = ModelCheckpoint(filepath=self.filepath, save_best_only=True)\n",
    "        history = self._model.fit(X_train, y_train,\n",
    "                                  epochs=self.nb_epochs,\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  validation_data=(X_val, y_val),\n",
    "                                  callbacks=[earlystopping, checkpointer]).history\n",
    "        return self._model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            if self.saved_model_destination is None:\n",
    "                return self._model.predict(X)\n",
    "            else:\n",
    "                loaded_model = load_model(self.saved_model_destination)\n",
    "                return loaded_model.predict(X)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(\"Model not saved, try .save() first.\")\n",
    "            \n",
    "    def save(self, saved_model_destination):\n",
    "        assert self._model is not None\n",
    "        self.saved_model_destination = saved_model_destination\n",
    "        self._model.save(self.saved_model_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b1d6090caff969cb1ca1699ba5829d709af2e9b8"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'input_size'  : (70, ), # = max_len\n",
    "    'output_size' : 1,\n",
    "    'train_params': {'batch_size': 512,\n",
    "                     'patience'  : 2,\n",
    "                     'nb_epochs' : 4},\n",
    "    'max_features': 200000,\n",
    "    'embeddings_size': 300,\n",
    "    'embeddings_matrix': embeddings_lookup_matrix,\n",
    "    'drop_rate': 0.1,\n",
    "    'loss'     : 'binary_crossentropy',\n",
    "    'optimizer': optimizers.Adam(),\n",
    "    'metrics'  : ['accuracy'],\n",
    "    'filepath' : './model.h5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "ea648d01590d56030684fbbb7afa20e1bccf52f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 70, 300)           60000000  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 70, 60)            86880     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 68, 32)            5792      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 60,094,849\n",
      "Trainable params: 94,849\n",
      "Non-trainable params: 60,000,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/4\n",
      "914285/914285 [==============================] - 25s 27us/step - loss: 0.1212 - acc: 0.9536 - val_loss: 0.1090 - val_acc: 0.9566\n",
      "Epoch 2/4\n",
      "914285/914285 [==============================] - 24s 26us/step - loss: 0.1044 - acc: 0.9585 - val_loss: 0.1047 - val_acc: 0.9582\n",
      "Epoch 3/4\n",
      "914285/914285 [==============================] - 23s 25us/step - loss: 0.0991 - acc: 0.9605 - val_loss: 0.1029 - val_acc: 0.9587\n",
      "Epoch 4/4\n",
      "914285/914285 [==============================] - 23s 25us/step - loss: 0.0949 - acc: 0.9620 - val_loss: 0.1024 - val_acc: 0.9589\n"
     ]
    }
   ],
   "source": [
    "basic_rnn = BasicRNN(model_params)\n",
    "basic_rnn.initialize()\n",
    "_ = basic_rnn.fit(X_train_seq_pad, y_train, X_val_seq_pad, y_val)\n",
    "basic_rnn.save('./basic_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c67ea18532fdf890189eac0338fbcde69800f77"
   },
   "source": [
    "#### Model Structure Overview\n",
    "- Layer 1: embedding layer. Number of parameters = 200000 x 300 = 60000000\n",
    "- Layer 2: LSTM layer. Number of parameters = ((300 + 60 + 1) x 60) x 4 = 86640 (QUESTIONABLE)\n",
    "- Layer 3: 1D conv filters (32). Number of parameters = 3 x 60 x 32 + 32 = 5792\n",
    "- Layer 4: fully connected layer + dropout.\n",
    "- Layer 5: sigmoid layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
